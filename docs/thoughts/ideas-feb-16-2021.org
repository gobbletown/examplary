https://github.com/mullikine/examplary

i wanted to do this like 6 months ago

a compiler for gpt-3 prompts

the idea is to compose prompts

compose prompts using a DSL, it generates a prompt which is like natural language but , like a 'repeat after me' command

somehow the dsl must encapsulate things like, using question-answer pairs,

and allegory

and doing that more efficiently and more structurally than simply remembering those rules

, so the dsl makes it easier to design prompts, and it simply rolls it all together into a prompt, which is essentially just a string which is then sent to the API

the API cant return per-token probabilties and have some other settings

http://github.com/mullikine/glossaries-gh/blob/master/openai.txt

https://storage.googleapis.com/gcs-vuse/prompt-design.html

so the API streams text to you

you give it a prompt and then set the 'stop sequence'

when it generates the stop sequence, it stops

the prompt is the input text, it tries to continue the text until it generates the stop sequence

there can be multiple stop sequences

that in itself would need to be encoded into the DSL somehow

the DSL should let you not only design the prompt, but compose prompts together, prompts within prompts

one prompt per function, so functions are designed by using prompts

so you functions can be composed of other functions, or functions which are essentially prompts

there isnt a single repository online which has yet found a way to orgnise prompts effectively

https://github.com/wgryc/gpt3-prompts

this is the best ive found

also, havent found yet any website which organises them

if it's lisp-like then the DSL can be used inside emacs easily

it would also make it super easy to create it

the easiest first step is simply curating prompts in an organised way

putting the prompts into a database in a format which also has the settings for the prompt.

temperature, a float value from 0-1 is the creativity level

that is part of a prompt. so a prompt is a string together with the settings, such as start, stop, restart sequences and temperature

it could be a yaml file together with some settings. that would work, i guess, a lot like a tenet, i guess

its a lot simpler

the yaml file would only describe prompts, the DSL would be completely separate from that

the DSL is just listp functions. very easy, dont even need to build anything. would take 2 seconds

ill try to put these example prompts into a git repository

so what's important to figure out in the DSL is its objectives, such as that distinction i just made between yaml files and the DSL

the DSL should compile to a sequence of requests to the API

not just sequences, but should have the ability to poll for more user input

so a little interactivity as its executing would be nice

maybe. but that maybe can come later. the first steps would be to curate prompts and then see if they can be composed to make bigger prompts

and if prompts can be composed more easily (ie. generate QA pairs) using the DSL to generate prompts

a prompt can be generated (to make a new prompt-function) or can be used in an existing prompt. a prompt is essentially just a function, but theres not really any DSL yet to describe how to compose them and build bigger programs with them

or to generate prompts from non-prompt string literals.

i guess the design is the hardest part. the rest is just creating macros

designing a DSL to generate prompts, and essentially maintain libraries of prompt functions

because prompt-engineering is going to become pretty big in the future i think

The DSL is always used to generate prompts. The output of the API would be considered to be another prompt which can be used. GPT-3 can be used to generate GPT-3 prompts. That's pretty ridiculous, but true

maybe there can be a prompt description file, which is loaded into an object as a convenience. Due to the homoiconicity of lisp, there would also be a () representation of the object

the prompt description file would be yaml, i guess

but composing prompts would all be done in lisp to make it trivial

GPT-4 is on its way.... and im guessing that when its announced in a few months, people will be able to showcase their GPT-3 stuff

at the moment theres a moratorium on that

so we don't really know what's out there

i have no idea how to monetise this

or get funding or anything like that

it might be cool to reward people who contribute to the prompts library when their prompts are used

and there could be a service based on ocean protocol which means that people dont need to reveal their secret prompts when they want to execute the prompts

if those prompts rely on other prompt libraries

this is making me think i should move my eth to streamr after i sell streamr for eth

move my eth to ocean, i mean

http://github.com/mullikine/emacs-openai-api-playground/blob/master/design.org

im making an emacs playground atm

its gonna be the best openai playground :P

i think i could beat basically anything thats out there

but having a DSL to compliment it would be awesome
